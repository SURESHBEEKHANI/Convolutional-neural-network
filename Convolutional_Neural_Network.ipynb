{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMHpVkblk9IS9ebH5+odtlu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Convolutional-neural-network/blob/main/Convolutional_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow library for machine learning tasks\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import necessary layers from TensorFlow's Keras API\n",
        "# Dense: Fully connected layer\n",
        "# Flatten: Flatten the input to a 1D array\n",
        "# Conv2D: Convolutional layer\n",
        "# MaxPooling2D: Max pooling layer\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# Import Sequential model from TensorFlow's Keras API\n",
        "# Sequential model is a linear stack of layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Import utility for categorical conversion\n",
        "# to_categorical: Converts a class vector (integers) to binary class matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Import Adam optimizer from TensorFlow's Keras API\n",
        "# Adam: Optimization algorithm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Import matplotlib for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import numpy for numerical operations\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "UDM2VGziooDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load database"
      ],
      "metadata": {
        "id": "9FyaqJxCpQSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The CIFAR-10 dataset is a collection of 60,000 32x32 color images in 10 different classes,\n",
        "# with 6,000 images per class. It is commonly used for training machine learning and computer vision models.\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Explanation of the loaded data:\n",
        "# x_train: This is the training set images. It contains 50,000 images of shape 32x32x3 (32x32 pixels and 3 color channels).\n",
        "# y_train: These are the labels for the training set images. Each label corresponds to one of the 10 classes.\n",
        "# x_test: This is the test set images. It contains 10,000 images of shape 32x32x3.\n",
        "# y_test: These are the labels for the test set images. Each label corresponds to one of the 10 classes."
      ],
      "metadata": {
        "id": "q78Vp4AjuSjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class labels\n",
        "# This list contains the names of the categories or classes that the images belong to.\n",
        "class_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Initialize the figure and subplots\n",
        "# This line sets up a grid of subplots (small plots) within a larger figure.\n",
        "# 2 rows and 5 columns means there will be 10 subplots in total.\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "\n",
        "# Iterate through the first 10 images\n",
        "# This loop goes through the first 10 images in the training dataset.\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Select the image and label\n",
        "    # x_train[i] is the image, and y_train[i] is the label (category) of that image.\n",
        "    image, label = x_train[i], y_train[i]\n",
        "\n",
        "    # Display the image\n",
        "    # This line shows the image on the current subplot.\n",
        "    ax.imshow(image, cmap='gray')\n",
        "\n",
        "    # Set the title with the class label\n",
        "    # This sets the title of the subplot to the name of the category of the image.\n",
        "    ax.set_title(f\"{class_labels[label.item()]}\")\n",
        "    # Turn off the axis\n",
        "    # This removes the axis ticks and labels for a cleaner look.\n",
        "    ax.axis('off')\n",
        "\n",
        "# Display the figure\n",
        "# This line shows the entire figure with all the subplots.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "faKoOmwlsm2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the image pixel values\n",
        "# Image pixel values range from 0 to 255. To make the model training process easier and more efficient,\n",
        "# we normalize these values to a range between 0 and 1.\n",
        "\n",
        "# Normalize the training set images\n",
        "# Convert the data type of x_train to float32 and then divide each pixel value by 255.0.\n",
        "# This scales the pixel values from the range [0, 255] to the range [0, 1].\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "\n",
        "# Normalize the test set images\n",
        "# Similarly, convert the data type of x_test to float32 and then divide each pixel value by 255.0.\n",
        "# This scales the pixel values from the range [0, 255] to the range [0, 1].\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Explanation:\n",
        "# - astype('float32') changes the data type of the image arrays to float32.\n",
        "# - Dividing by 255.0 normalizes the pixel values to be between 0 and 1.\n"
      ],
      "metadata": {
        "id": "eAouXTBhu_eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_train to one-hot encoding\n",
        "# y_train contains the class labels as integers. One-hot encoding converts these labels\n",
        "# into binary vectors, where each vector has a length equal to the number of classes (10 in this case).\n",
        "# For example, if the class label is 2, the one-hot encoded vector will be [0, 0, 1, 0, 0, 0, 0, 0, 0, 0].\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "# Convert y_test to one-hot encoding\n",
        "# Similarly, convert the class labels in y_test to one-hot encoded vectors.\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "Jga4-bJNwvcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the training and test datasets\n",
        "# The shape attribute gives the dimensions of the array.\n",
        "# For images, the shape will be (number of images, height, width, number of color channels).\n",
        "# For labels, the shape will be (number of images, number of classes).\n",
        "\n",
        "# Shape of x_train\n",
        "# This will print the shape of the training images array.\n",
        "# Expected output: (50000, 32, 32, 3)\n",
        "# 50000 images, each 32x32 pixels, with 3 color channels (RGB).\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "\n",
        "# Shape of y_train\n",
        "# This will print the shape of the training labels array.\n",
        "# Expected output: (50000, 10)\n",
        "# 50000 labels, each converted to a one-hot encoded vector of length 10.\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "\n",
        "# Shape of x_test\n",
        "# This will print the shape of the test images array.\n",
        "# Expected output: (10000, 32, 32, 3)\n",
        "# 10000 images, each 32x32 pixels, with 3 color channels (RGB).\n",
        "print(\"Shape of x_test:\", x_test.shape)\n",
        "\n",
        "# Shape of y_test\n",
        "# This will print the shape of the test labels array.\n",
        "# Expected output: (10000, 10)\n",
        "# 10000 labels, each converted to a one-hot encoded vector of length 10.\n",
        "print(\"Shape of y_test:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "PPyxJ9LjycHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model as Sequential\n",
        "# A Sequential model is a linear stack of layers. We add layers to the model one at a time.\n",
        "model = Sequential()\n",
        "\n",
        "# Add a convolutional layer\n",
        "# Conv2D is a 2D convolutional layer. It creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
        "# 32 filters: The number of filters in the convolutional layer, each detecting a different feature.\n",
        "# (3, 3): The size of the convolution kernel (3x3).\n",
        "# activation='relu': The activation function to apply after the convolution. ReLU (Rectified Linear Unit) introduces non-linearity.\n",
        "# input_shape=(32, 32, 3): The shape of the input data. 32x32 is the size of the image, and 3 is the number of color channels (RGB).\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "# Add a max pooling layer\n",
        "# MaxPooling2D is a pooling layer that performs max pooling operation. It reduces the spatial dimensions (height and width) of the input volume.\n",
        "# pool_size=(2, 2): The size of the pooling window (2x2).\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add additional convolutional and pooling layers to deepen the network\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output from the convolutional layers\n",
        "# Flatten converts the 2D matrix of features into a 1D vector\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer\n",
        "# Dense is a fully connected layer. Each neuron receives input from all the neurons in the previous layer.\n",
        "# 128 neurons in this layer.\n",
        "# activation='relu': The activation function to apply after the linear combination.\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "# The output layer has a number of neurons equal to the number of classes for object classification.\n",
        "# Assuming we have 10 classes for simplicity.\n",
        "# activation='softmax': Softmax activation function is used for multi-class classification.\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "# The compile step specifies the loss function, optimizer with a specific learning rate, and metrics for evaluation.\n",
        "# categorical_crossentropy: The loss function used for multi-class classification.\n",
        "# Adam optimizer with a learning rate of 0.001.\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "# The summary method prints a summary of the model's architecture.\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "JqEEH_685p6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# model.fit() is used to train the neural network model on the training data.\n",
        "# It adjusts the model's weights to minimize the specified loss function and improve accuracy.\n",
        "# x_train: Training data, typically input images.\n",
        "# y_train: Training labels, corresponding to the target outputs for each input image.\n",
        "# batch_size: Number of samples per gradient update. It defines how many samples are processed before updating the model's parameters.\n",
        "# epochs: Number of epochs (iterations over the entire x_train and y_train data) to train the model.\n",
        "# validation_data: Optional tuple (x_test, y_test) on which to evaluate the loss and any model metrics at the end of each epoch.\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=20,\n",
        "          validation_data=(x_test,y_test))\n"
      ],
      "metadata": {
        "id": "ATptE5pW8MJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "pIdB6dzxCmRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "Kqiyd0UfCwzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_images_to_display = 20\n",
        "num_columns = 4\n",
        "num_rows = (num_images_to_display + num_columns - 1) // num_columns\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 10))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < num_images_to_display:\n",
        "        ax.imshow(x_test[i])\n",
        "        actual_label = class_labels[np.argmax(y_test[i])]\n",
        "        predicted_label = class_labels[np.argmax(pred[i])]\n",
        "        ax.set_title(f\"Actual: {actual_label}, Predicted: {predicted_label}\")\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4akAj8_LCYKK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}