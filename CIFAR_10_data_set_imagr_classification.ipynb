{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNWMWoqD0THw0tmZXIWuBg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Convolutional-neural-network/blob/main/CIFAR_10_data_set_imagr_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYERXxPxTuXV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf  # Import the TensorFlow library for building neural networks\n",
        "import matplotlib.pyplot as plt  # Import the Matplotlib library for data visualization\n",
        "from tensorflow.keras import models, layers  # Import layers and models from TensorFlow.keras for building sequential models\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code loads the data for training and testing datasets.\n",
        "# It uses the CIFAR-100 dataset, which contains images categorized into 100 classes.\n",
        "\n",
        "# Load the CIFAR-100 dataset for training and testing\n",
        "# The dataset is split into two parts: training data (x_train, y_train) and testing data (x_test, y_test).\n",
        "# x_train and x_test contain images, while y_train and y_test contain labels (categories) for those images.\n",
        "\n",
        "(x_train, y_train), (x_test,y_test) = tf.keras.datasets.cifar100.load_data()\n"
      ],
      "metadata": {
        "id": "lC5ionJnV0CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shape Of Dataset"
      ],
      "metadata": {
        "id": "uGp9mPnaYKyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code prints the shape of the training and testing datasets.\n",
        "# \"Shape\" means the size or number of elements in each dataset.\n",
        "\n",
        "# Print the shape of the training data for input features (X_train)\n",
        "# This tells us how many rows and columns are in the X_train dataset.\n",
        "print(\"Print the shape of X_train:\", x_train.shape)\n",
        "\n",
        "# Print the shape of the testing data for input features (X_test)\n",
        "# This tells us how many rows and columns are in the X_test dataset.\n",
        "print(\"Print the shape of X_test:\", x_test.shape)\n",
        "\n",
        "# Print the shape of the training data for output labels (y_train)\n",
        "# This tells us how many rows and columns are in the y_train dataset.\n",
        "print(\"Print the shape of y_train:\", y_train.shape)\n",
        "\n",
        "# Print the shape of the testing data for output labels (y_test)\n",
        "# This tells us how many rows and columns are in the y_test dataset.\n",
        "print(\"Print the shape of y_test:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "wpHUsSx8WbRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a figure to display the images with specific size (20x4 inches)\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "# Loop through the first 'n' images from the test data\n",
        "for i in range(n):\n",
        "    # Create a subplot at a specific position within the figure\n",
        "    #  - 2 rows, n columns, subplot at index (i + 1)\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "\n",
        "    # Reshape the image data from a flat array to a 28x28 grid (representing the image)\n",
        "    image = x_test[i].reshape(32, 32,3)\n",
        "\n",
        "    # Display the reshaped image on the subplot\n",
        "    plt.imshow(image)\n",
        "\n",
        "\n",
        "\n",
        "    # Hide the x-axis and y-axis labels and tick marks for cleaner presentation\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# Display the figure containing the subplots with the handwritten digits\n",
        "plt.show()\n",
        "\n",
        "# Close the figure after it's displayed (optional, the figure will close automatically after program execution)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "rPZZmjD8ZSs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping Data in \"Channel Last\" format for TensorFlow backend\n",
        "x_train = x_train.reshape(x_train.shape[0], 32, 32,3)\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bj4mk_zJ7Een"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to floating point and normalizing pixel values in range [0, 1]\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "rGLikcT17Q6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping Labels in One-hot encoding for Multi-class Classification\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=100)\n",
        "y_test = to_categorical(y_test, num_classes=100)\n",
        "\n",
        "# Seeing updated Shapes\n",
        "print(\"x_train Shape :\", x_train.shape)\n",
        "print(\"y_train Shape :\", y_train.shape)\n",
        "print(\"x_test Shape :\", x_test.shape)\n",
        "print(\"y_test Shape :\", y_test.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G31Db9-S7Vzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line imports a special function called 'Sequential' from a library named 'keras.models'\n",
        "# This function helps create a type of neural network model, like building blocks one after another\n",
        "from keras.models import Sequential\n",
        "\n",
        "# These lines import special functions from a library named 'keras.layers'\n",
        "# Imagine these functions as different tools used to create the neural network\n",
        "#  - 'Dense' creates a fully connected layer, where all data points from one layer connect to all data points in the next\n",
        "#  - 'Flatten' takes data that might have multiple dimensions (like a width and height for an image) and flattens it into a single line\n",
        "from keras.layers import Dense, Flatten\n",
        "\n",
        "# These lines import more functions from 'keras.layers'\n",
        "#  - 'Conv2D' creates a convolutional layer, which is like a filter that looks for specific patterns in images\n",
        "#  - 'MaxPooling2D' is another tool that simplifies the data by choosing the most important parts from a small area of the image\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CoZXFdGR7dqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #img_rows, img_cols, channels = 28, 28, 1 # 1 for greyscale images and 3 for rgb images\n",
        "\n",
        "# classes=10\n",
        "# Define the dimensions of the input image\n",
        "img_rows, img_cols, channels = 32, 32, 3  # 1 for greyscale images and 3 for rgb images\n",
        "\n",
        "# Define the number of filters for each layer of the CNN\n",
        "filters = [60, 120, 240 ,340, 540]  # These are the number of filters in each layer of the CNN\n",
        "\n",
        "# Define the number of classes for classification\n",
        "classes = 100  # This is the number of different categories that the CNN will classify images into\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8q4sfupd7jmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Creating Model\n",
        "\n",
        "model=Sequential() #Sequential is a container to store layers\n",
        "model.add(Conv2D(filters[0],(3,3),padding='same',\\\n",
        "                 activation='relu',input_shape=(img_rows,img_cols, channels)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #For reducing image size\n",
        "\n",
        "# (dim+pad-kernel)/2   (28 +3 -3)/2 = 14\n",
        "model.add(Conv2D(filters[1],(2,2),padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# (dim+pad-kernel)/2   (14 +2 -2)/2 = 7\n",
        "model.add(Conv2D(filters[2],(2,2),padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# (dim+pad-kernel)/2   (7 +2 -2)/2 = 3\n",
        "\n",
        "model.add(Conv2D(filters[3],(2,2),padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters[4],(2,2),padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# (dim+pad-kernel)/2   (3 +2 -2)/2 = 1\n",
        "model.add(Flatten())\n",
        "model.add(Dense(160,activation='relu'))\n",
        "model.add(Dense(classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        ""
      ],
      "metadata": {
        "id": "OsewKJEV7yOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZtFtWjcc8UEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Model\n",
        "model.fit(x_train, y_train, validation_split= 0.2, epochs=15, batch_size=40, verbose=1)\n",
        "# model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "id": "wSQCTga88dTf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}