{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdD+fA/Br2TuqdxFbmOZYf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Convolutional-neural-network/blob/main/CIFAR_10_data_set_imagr_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYERXxPxTuXV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf  # Import the TensorFlow library for building neural networks\n",
        "import matplotlib.pyplot as plt  # Import the Matplotlib library for data visualization\n",
        "from tensorflow.keras import models, layers  # Import layers and models from TensorFlow.keras for building sequential models\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code loads the data for training and testing datasets.\n",
        "# It uses the CIFAR-100 dataset, which contains images categorized into 100 classes.\n",
        "\n",
        "# Load the CIFAR-100 dataset for training and testing\n",
        "# The dataset is split into two parts: training data (x_train, y_train) and testing data (x_test, y_test).\n",
        "# x_train and x_test contain images, while y_train and y_test contain labels (categories) for those images.\n",
        "\n",
        "(x_train, x_test), (y_train, y_test) = tf.keras.datasets.cifar100.load_data()\n"
      ],
      "metadata": {
        "id": "lC5ionJnV0CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shape Of Dataset"
      ],
      "metadata": {
        "id": "uGp9mPnaYKyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code prints the shape of the training and testing datasets.\n",
        "# \"Shape\" means the size or number of elements in each dataset.\n",
        "\n",
        "# Print the shape of the training data for input features (X_train)\n",
        "# This tells us how many rows and columns are in the X_train dataset.\n",
        "print(\"Print the shape of X_train:\", x_train.shape)\n",
        "\n",
        "# Print the shape of the testing data for input features (X_test)\n",
        "# This tells us how many rows and columns are in the X_test dataset.\n",
        "print(\"Print the shape of X_test:\", x_test.shape)\n",
        "\n",
        "# Print the shape of the training data for output labels (y_train)\n",
        "# This tells us how many rows and columns are in the y_train dataset.\n",
        "print(\"Print the shape of y_train:\", y_train.shape)\n",
        "\n",
        "# Print the shape of the testing data for output labels (y_test)\n",
        "# This tells us how many rows and columns are in the y_test dataset.\n",
        "print(\"Print the shape of y_test:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "wpHUsSx8WbRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPZZmjD8ZSs-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}